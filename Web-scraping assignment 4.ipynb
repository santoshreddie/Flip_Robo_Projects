{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets import necessary libraries for our work\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import *\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from selenium.webdriver.support import  expected_conditions as ec"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url= https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A)Rank\n",
    "B)Name\n",
    "C)Artist\n",
    "D)Upload date\n",
    "E)Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of most-viewed YouTube videos - Wikipedia\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Upload date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No.</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.</th>\n",
       "      <td>\"Baby Shark Dance\"[22]</td>\n",
       "      <td>Pinkfong Kids' Songs &amp; Stories</td>\n",
       "      <td>8.71</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.</th>\n",
       "      <td>\"Despacito\"[24]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>7.38</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.</th>\n",
       "      <td>\"Johny Johny Yes Papa\"[25]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>5.41</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.</th>\n",
       "      <td>\"Shape of You\"[26]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>5.34</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.</th>\n",
       "      <td>\"See You Again\"[27]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.13</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.</th>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[30]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.44</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.</th>\n",
       "      <td>\"Uptown Funk\"[31]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.19</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.</th>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[32]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.12</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.</th>\n",
       "      <td>\"Bath Song\"[33]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>4.10</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.</th>\n",
       "      <td>\"Gangnam Style\"[34]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.08</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.</th>\n",
       "      <td>\"Phonics Song with Two Words\"[36]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>3.90</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.</th>\n",
       "      <td>\"Sugar\"[37]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.48</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.</th>\n",
       "      <td>\"Sorry\"[38]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.44</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.</th>\n",
       "      <td>\"Dame Tu Cosita\"[39]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>3.37</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.</th>\n",
       "      <td>\"Roar\"[40]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.36</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.</th>\n",
       "      <td>\"Counting Stars\"[41]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.31</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.</th>\n",
       "      <td>\"Thinking Out Loud\"[42]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.26</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.</th>\n",
       "      <td>\"Dark Horse\"[43]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.08</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.</th>\n",
       "      <td>\"Faded\"[44]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.07</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.</th>\n",
       "      <td>\"Shake It Off\"[45]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>3.06</td>\n",
       "      <td>August 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.</th>\n",
       "      <td>\"Wheels on the Bus\"[46]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.05</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.</th>\n",
       "      <td>\"Lean On\"[47]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.04</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.</th>\n",
       "      <td>\"Bailando\"[48]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.04</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.</th>\n",
       "      <td>\"Girls Like You\"[49]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.04</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.</th>\n",
       "      <td>\"Let Her Go\"[50]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.00</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.</th>\n",
       "      <td>\"Mi Gente\"[51]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>2.92</td>\n",
       "      <td>June 29, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.</th>\n",
       "      <td>\"Perfect\"[52]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>2.86</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.</th>\n",
       "      <td>\"Hello\"[53]</td>\n",
       "      <td>Adele</td>\n",
       "      <td>2.84</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.</th>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[54]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>2.84</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30.</th>\n",
       "      <td>\"Axel F\"[55]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>2.82</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Video name  \\\n",
       "No.                                                    \n",
       "1.                            \"Baby Shark Dance\"[22]   \n",
       "2.                                   \"Despacito\"[24]   \n",
       "3.                        \"Johny Johny Yes Papa\"[25]   \n",
       "4.                                \"Shape of You\"[26]   \n",
       "5.                               \"See You Again\"[27]   \n",
       "6.    \"Masha and the Bear – Recipe for Disaster\"[30]   \n",
       "7.                                 \"Uptown Funk\"[31]   \n",
       "8.   \"Learning Colors – Colorful Eggs on a Farm\"[32]   \n",
       "9.                                   \"Bath Song\"[33]   \n",
       "10.                              \"Gangnam Style\"[34]   \n",
       "11.                \"Phonics Song with Two Words\"[36]   \n",
       "12.                                      \"Sugar\"[37]   \n",
       "13.                                      \"Sorry\"[38]   \n",
       "14.                             \"Dame Tu Cosita\"[39]   \n",
       "15.                                       \"Roar\"[40]   \n",
       "16.                             \"Counting Stars\"[41]   \n",
       "17.                          \"Thinking Out Loud\"[42]   \n",
       "18.                                 \"Dark Horse\"[43]   \n",
       "19.                                      \"Faded\"[44]   \n",
       "20.                               \"Shake It Off\"[45]   \n",
       "21.                          \"Wheels on the Bus\"[46]   \n",
       "22.                                    \"Lean On\"[47]   \n",
       "23.                                   \"Bailando\"[48]   \n",
       "24.                             \"Girls Like You\"[49]   \n",
       "25.                                 \"Let Her Go\"[50]   \n",
       "26.                                   \"Mi Gente\"[51]   \n",
       "27.                                    \"Perfect\"[52]   \n",
       "28.                                      \"Hello\"[53]   \n",
       "29.           \"Waka Waka (This Time for Africa)\"[54]   \n",
       "30.                                     \"Axel F\"[55]   \n",
       "\n",
       "                           Uploader Views (billions)        Upload date  \n",
       "No.                                                                      \n",
       "1.   Pinkfong Kids' Songs & Stories             8.71      June 17, 2016  \n",
       "2.                       Luis Fonsi             7.38   January 12, 2017  \n",
       "3.                      LooLoo Kids             5.41    October 8, 2016  \n",
       "4.                       Ed Sheeran             5.34   January 30, 2017  \n",
       "5.                      Wiz Khalifa             5.13      April 6, 2015  \n",
       "6.                       Get Movies             4.44   January 31, 2012  \n",
       "7.                      Mark Ronson             4.19  November 19, 2014  \n",
       "8.                      Miroshka TV             4.12  February 27, 2018  \n",
       "9.       Cocomelon – Nursery Rhymes             4.10        May 2, 2018  \n",
       "10.                             Psy             4.08      July 15, 2012  \n",
       "11.                       ChuChu TV             3.90      March 6, 2014  \n",
       "12.                        Maroon 5             3.48   January 14, 2015  \n",
       "13.                   Justin Bieber             3.44   October 22, 2015  \n",
       "14.                       El Chombo             3.37      April 5, 2018  \n",
       "15.                      Katy Perry             3.36  September 5, 2013  \n",
       "16.                     OneRepublic             3.31       May 31, 2013  \n",
       "17.                      Ed Sheeran             3.26    October 7, 2014  \n",
       "18.                      Katy Perry             3.08  February 20, 2014  \n",
       "19.                     Alan Walker             3.07   December 3, 2015  \n",
       "20.                    Taylor Swift             3.06    August 18, 2014  \n",
       "21.      Cocomelon – Nursery Rhymes             3.05       May 24, 2018  \n",
       "22.                     Major Lazer             3.04     March 22, 2015  \n",
       "23.                Enrique Iglesias             3.04     April 11, 2014  \n",
       "24.                        Maroon 5             3.04       May 31, 2018  \n",
       "25.                       Passenger             3.00      July 25, 2012  \n",
       "26.                        J Balvin             2.92      June 29, 2017  \n",
       "27.                      Ed Sheeran             2.86   November 9, 2017  \n",
       "28.                           Adele             2.84   October 22, 2015  \n",
       "29.                         Shakira             2.84       June 4, 2010  \n",
       "30.                      Crazy Frog             2.82      June 16, 2009  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting the url variable to the link through which we want to scrape\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "\n",
    "#getting the companents of the page to scrape the details\n",
    "page = requests.get(url)\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)\n",
    "\n",
    "#here we ar finding the table tags there are many tables in the we page we only need one table\n",
    "#so i will find that one by indexing we can see here\n",
    "table = soup.find_all('table', class_=\"wikitable sortable\")[0]\n",
    "\n",
    "#actually there are many methods for extracting tables from the website here \n",
    "#i am using panda method for extracting the table usign the method pd.read_html()\n",
    "#and conerting te minto string so that we can convert the table\n",
    "dfs = pd.read_html(str(table))[0]\n",
    "\n",
    "\n",
    "dfs = dfs.drop(30, axis = 0) # we have column which makes no sence and we droped it using drop()\n",
    "dfs = dfs.set_index('No.') #setting the index of rank of the videos\n",
    "df = dfs.drop([\"Note\", \"Unnamed: 6\"], axis = 1)#and we have two unwanted columns and we dropped them\n",
    "df #displaying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "2.Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A)Match title (I.e. 1stODI)\n",
    "B)Series\n",
    "C)Place\n",
    "D)Date\n",
    "E)Time\n",
    "Note: -From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Board of Control for Cricket in India\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match_Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>ICC World Test Championship</td>\n",
       "      <td>Friday  18  June</td>\n",
       "      <td>15:00 IST</td>\n",
       "      <td>The Ageas Bowl, Southampton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Wednesday  04  August</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>Trent Bridge, Nottingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Thursday  12  August</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>Lord's, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3rd Test</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Wednesday  25  August</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>Headingley, Leeds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4th Test</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Thursday  02  September</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>The Oval, London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5th Test</td>\n",
       "      <td>England v India 2021</td>\n",
       "      <td>Friday  10  September</td>\n",
       "      <td>15:30 IST</td>\n",
       "      <td>Old Trafford, Manchester</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match_Title                       Series                      Date  \\\n",
       "0       Final  ICC World Test Championship          Friday  18  June   \n",
       "1    1st Test         England v India 2021     Wednesday  04  August   \n",
       "2    2nd Test         England v India 2021      Thursday  12  August   \n",
       "3    3rd Test         England v India 2021     Wednesday  25  August   \n",
       "4    4th Test         England v India 2021   Thursday  02  September   \n",
       "5    5th Test         England v India 2021     Friday  10  September   \n",
       "\n",
       "        Time                        Place  \n",
       "0  15:00 IST  The Ageas Bowl, Southampton  \n",
       "1  15:30 IST     Trent Bridge, Nottingham  \n",
       "2  15:30 IST               Lord's, London  \n",
       "3  15:30 IST            Headingley, Leeds  \n",
       "4  15:30 IST             The Oval, London  \n",
       "5  15:30 IST     Old Trafford, Manchester  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the information of driver for accesig the driver for automation\n",
    "driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "\n",
    "#naviagting to the url\n",
    "driver.get('https://www.bcci.tv/')\n",
    "\n",
    "\n",
    "#Getting required dropdown using this webelement\n",
    "driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]\").click()\n",
    "\n",
    "\n",
    "#after dropdow shown up we have to go to fixture to go to that page\n",
    "driver.find_element_by_xpath(\"/html/body/div[3]/div/div[2]/div[2]/nav/ul/li[1]/div[2]/div/ul/li[1]/a\").click()\n",
    "\n",
    "#setting the url variable to the link through which we want\n",
    "url = driver.current_url\n",
    "\n",
    "#getting the companents of the page to scrape the details\n",
    "#This is the new url which the current page is and we want it to scrape the currrent page\n",
    "page = requests.get(url)\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)\n",
    "\n",
    "#creating the empty list for storing the data\n",
    "series = []\n",
    "Date = []\n",
    "Time = []\n",
    "match_title = []\n",
    "place = []\n",
    "\n",
    "#first thing here i am going to use list indexing so thta we can use that to divivde the list for iur desired results\n",
    "#getiing title and place details from the page\n",
    "p_t = []\n",
    "t_p = soup.find_all('p', class_=\"fixture__additional-info\") \n",
    "for i in t_p:\n",
    "    p_t.append(i.text.split(\"\\n\"))\n",
    "    \n",
    "for i in p_t:\n",
    "    match_title.append(i[1]) #here i am using indexing from same list dividing two other details\n",
    "    place.append(i[2])\n",
    "\n",
    "#now gathering details for the series\n",
    "seri = soup.find_all('span', class_=\"u-unskewed-text fixture__tournament-label u-truncated\")\n",
    "for i in seri:\n",
    "    series.append(i.text)\n",
    "    \n",
    "\n",
    "#getting details for time\n",
    "time = soup.find_all(\"span\", class_ =\"fixture__time\")\n",
    "for i in time:\n",
    "    Time.append(i.text.strip().replace(\"\\n\", \" \"))\n",
    "    \n",
    "#atlast getting details for the date\n",
    "dat = []\n",
    "d = soup.find_all(\"div\", class_='fixture__datetime desktop-only')\n",
    "for i in d:\n",
    "    dat.append(i.text.replace(\"\\n\", \" \"))\n",
    "\n",
    "for i in dat:\n",
    "    Date.append(i[:-14])\n",
    "    \n",
    "#Now lets create database to store the data that we have collected\n",
    "icc = pd.DataFrame({})\n",
    "icc[\"Match_Title\"] = match_title\n",
    "icc[\"Series\"] = series\n",
    "icc[\"Date\"] = Date\n",
    "icc[\"Time\"] = Time\n",
    "icc[\"Place\"] = place\n",
    "\n",
    "#saving the dataframe to csv\n",
    "icc.to_csv(\"icc.csv\")\n",
    "\n",
    "#displaying results\n",
    "icc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "3.Scrape the details of selenium exception from guru99.com.\n",
    "Url= https://www.guru99.com/You need to find following details:\n",
    "A)Name\n",
    "B)Description\n",
    "Note: -From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the information of driver for accesig the driver for automation\n",
    "driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "\n",
    "#naviagting to the url\n",
    "driver.get('https://www.guru99.com/')\n",
    "\n",
    "#now from there we have to navigate to selenium page\n",
    "driver.find_element_by_xpath(\"/html/body/div[2]/section[4]/div/div/div/div/div/div/div/div[1]/div/ul[1]/li[3]/a\").click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#closing the button for going further\n",
    "driver.find_element_by_xpath(\"//*[@id='cbox']/div/div/div/div/div[1]\")\n",
    "\n",
    "\n",
    "#now we have to navigate to exception handling\n",
    "driver.find_element_by_xpath('//a[@href=\"/exception-handling-selenium.html\"]/strong').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selenium Exception Handling (Common Exceptions List)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception_name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can't be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n't sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception_name  \\\n",
       "1            ElementNotVisibleException   \n",
       "2         ElementNotSelectableException   \n",
       "3                NoSuchElementException   \n",
       "4                  NoSuchFrameException   \n",
       "5               NoAlertPresentException   \n",
       "6                 NoSuchWindowException   \n",
       "7        StaleElementReferenceException   \n",
       "8              SessionNotFoundException   \n",
       "9                      TimeoutException   \n",
       "10                   WebDriverException   \n",
       "11            ConnectionClosedException   \n",
       "12     ElementClickInterceptedException   \n",
       "13      ElementNotInteractableException   \n",
       "14             ErrorInResponseException   \n",
       "15  ErrorHandler.UnknownServerException   \n",
       "16         ImeActivationFailedException   \n",
       "17             ImeNotAvailableException   \n",
       "18         InsecureCertificateException   \n",
       "19             InvalidArgumentException   \n",
       "20         InvalidCookieDomainException   \n",
       "21          InvalidCoordinatesException   \n",
       "22          InvalidElementStateExceptio   \n",
       "23            InvalidSessionIdException   \n",
       "24       InvalidSwitchToTargetException   \n",
       "25                  JavascriptException   \n",
       "26                        JsonException   \n",
       "27             NoSuchAttributeException   \n",
       "28       MoveTargetOutOfBoundsException   \n",
       "29               NoSuchContextException   \n",
       "30                NoSuchCookieException   \n",
       "31                    NotFoundException   \n",
       "32          RemoteDriverServerException   \n",
       "33                  ScreenshotException   \n",
       "34           SessionNotCreatedException   \n",
       "35           UnableToSetCookieException   \n",
       "36           UnexpectedTagNameException   \n",
       "37              UnhandledAlertException   \n",
       "38      UnexpectedAlertPresentException   \n",
       "39               UnknownMethodException   \n",
       "40          UnreachableBrowserException   \n",
       "41          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "1   This type of Selenium exception occurs when an...  \n",
       "2   This Selenium exception occurs when an element...  \n",
       "3   This Exception occurs if an element could not ...  \n",
       "4   This Exception occurs if the frame target to b...  \n",
       "5   This Exception occurs when you switch to no pr...  \n",
       "6   This Exception occurs if the window target to ...  \n",
       "7   This Selenium exception occurs happens when th...  \n",
       "8   The WebDriver is acting after you quit the bro...  \n",
       "9   Thrown when there is not enough time for a com...  \n",
       "10  This Exception takes place when the WebDriver ...  \n",
       "11  This type of Exception takes place when there ...  \n",
       "12  The command may not be completed as the elemen...  \n",
       "13  This Selenium exception is thrown when any ele...  \n",
       "14  This happens while interacting with the Firefo...  \n",
       "15  Exception is used as a placeholder in case if ...  \n",
       "16  This expectation will occur when IME engine ac...  \n",
       "17    It takes place when IME support is unavailable.  \n",
       "18  Navigation made the user agent to hit a certif...  \n",
       "19  It occurs when an argument does not belong to ...  \n",
       "20  This happens when you try to add a cookie unde...  \n",
       "21  This type of Exception matches an interacting ...  \n",
       "22  It occurs when command can't be finished when ...  \n",
       "23  This Exception took place when the given sessi...  \n",
       "24  This occurs when the frame or window target to...  \n",
       "25  This issue occurs while executing JavaScript g...  \n",
       "26  It occurs when you afford to get the session w...  \n",
       "27  This kind of Exception occurs when the attribu...  \n",
       "28  It takes place if the target provided to the A...  \n",
       "29           ContextAware does mobile device testing.  \n",
       "30  This Exception occurs when no cookie matching ...  \n",
       "31  This Exception is a subclass of WebDriverExcep...  \n",
       "32  This Selenium exception is thrown when the ser...  \n",
       "33            It is not possible to capture a screen.  \n",
       "34  It happens when a new session could not be suc...  \n",
       "35  This occurs if a driver is unable to set a coo...  \n",
       "36  Happens if a support class did not get a web e...  \n",
       "37  This expectation occurs when there is an alert...  \n",
       "38  It occurs when there is the appearance of an u...  \n",
       "39  This Exception happens when the requested comm...  \n",
       "40  This Exception occurs only when the browser is...  \n",
       "41  This occurs when remote WebDriver does n't sen...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting the url variable to the link through which we want\n",
    "url = driver.current_url\n",
    "\n",
    "#getting the companents of the page to scrape the details\n",
    "#This is the new url which the current page is and we want it to scrape the currrent page\n",
    "page = requests.get(url)\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)\n",
    "\n",
    "#creating the empty list for storing the data\n",
    "container = soup.find_all(\"table\", class_=\"table table-striped\")\n",
    "\n",
    "#here also i am using pandas read.html method to extract the table \n",
    "exception = pd.read_html(str(container))[0]\n",
    "\n",
    "#and in the table we have one unnecessary row so i removed it to make it readable\n",
    "new = exception.drop(0, axis = 0)\n",
    "\n",
    "#there are no column now w will set the those colummns\n",
    "new.columns = [\"Exception_name\", \"Description\"]\n",
    "\n",
    "#saving the exceptions file in csv file\n",
    "new.to_csv(\"exception.csv\")\n",
    "\n",
    "#Displaying the dataframe\n",
    "new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "4. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)\n",
    "D) GSDP(17-18)\n",
    "E) Share(2017)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDP of Indian states - StatisticsTimes.com\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th colspan=\"2\" halign=\"left\">GSDP (Cr INR at Current prices)</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP ($billion)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">GSDP (Cr INR at 2011-12 prices)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>19-20</th>\n",
       "      <th>18-19</th>\n",
       "      <th>18-19</th>\n",
       "      <th>2019</th>\n",
       "      <th>19-20</th>\n",
       "      <th>18-19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2632792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "      <td>-</td>\n",
       "      <td>2039074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1845853</td>\n",
       "      <td>1630208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "      <td>1312929</td>\n",
       "      <td>1215307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1687818</td>\n",
       "      <td>1584764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "      <td>1166817</td>\n",
       "      <td>1123982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1502899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "      <td>-</td>\n",
       "      <td>1186379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1631977</td>\n",
       "      <td>1493127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "      <td>1156039</td>\n",
       "      <td>1091077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1253832</td>\n",
       "      <td>1089898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "      <td>793223</td>\n",
       "      <td>739525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1020989</td>\n",
       "      <td>942586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "      <td>711627</td>\n",
       "      <td>677428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972782</td>\n",
       "      <td>862957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "      <td>672018</td>\n",
       "      <td>621301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969604</td>\n",
       "      <td>861031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "      <td>663258</td>\n",
       "      <td>612828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906672</td>\n",
       "      <td>809592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "      <td>561801</td>\n",
       "      <td>522009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "      <td>-</td>\n",
       "      <td>559412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856112</td>\n",
       "      <td>774870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "      <td>634408</td>\n",
       "      <td>590569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831610</td>\n",
       "      <td>734163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "      <td>572240</td>\n",
       "      <td>531085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611804</td>\n",
       "      <td>530363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "      <td>414977</td>\n",
       "      <td>375651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574760</td>\n",
       "      <td>526376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "      <td>418868</td>\n",
       "      <td>397669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521275</td>\n",
       "      <td>487805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "      <td>396499</td>\n",
       "      <td>376877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "      <td>-</td>\n",
       "      <td>234048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329180</td>\n",
       "      <td>304063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "      <td>243477</td>\n",
       "      <td>231182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328598</td>\n",
       "      <td>297204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "      <td>240036</td>\n",
       "      <td>224986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "      <td>-</td>\n",
       "      <td>193273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "      <td>-</td>\n",
       "      <td>112755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165472</td>\n",
       "      <td>153845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "      <td>124403</td>\n",
       "      <td>117851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80449</td>\n",
       "      <td>73170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "      <td>63408</td>\n",
       "      <td>57787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55984</td>\n",
       "      <td>49845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "      <td>40583</td>\n",
       "      <td>36963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "      <td>-</td>\n",
       "      <td>31192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38253</td>\n",
       "      <td>34433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "      <td>25093</td>\n",
       "      <td>23013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36572</td>\n",
       "      <td>33481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "      <td>26695</td>\n",
       "      <td>24682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32496</td>\n",
       "      <td>28723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "      <td>20017</td>\n",
       "      <td>18722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.0</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31790</td>\n",
       "      <td>27870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "      <td>20673</td>\n",
       "      <td>19300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.0</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "      <td>-</td>\n",
       "      <td>17647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31.0</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "      <td>-</td>\n",
       "      <td>16676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32.0</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26503</td>\n",
       "      <td>22287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "      <td>18797</td>\n",
       "      <td>16478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33.0</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Rank                      State GSDP (Cr INR at Current prices)           \\\n",
       "    Rank                      State                           19-20    18-19   \n",
       "0    1.0                Maharashtra                               -  2632792   \n",
       "1    2.0                 Tamil Nadu                         1845853  1630208   \n",
       "2    3.0              Uttar Pradesh                         1687818  1584764   \n",
       "3    4.0                    Gujarat                               -  1502899   \n",
       "4    5.0                  Karnataka                         1631977  1493127   \n",
       "5    6.0                West Bengal                         1253832  1089898   \n",
       "6    7.0                  Rajasthan                         1020989   942586   \n",
       "7    8.0             Andhra Pradesh                          972782   862957   \n",
       "8    9.0                  Telangana                          969604   861031   \n",
       "9   10.0             Madhya Pradesh                          906672   809592   \n",
       "10  11.0                     Kerala                               -   781653   \n",
       "11  12.0                      Delhi                          856112   774870   \n",
       "12  13.0                    Haryana                          831610   734163   \n",
       "13  14.0                      Bihar                          611804   530363   \n",
       "14  15.0                     Punjab                          574760   526376   \n",
       "15  16.0                     Odisha                          521275   487805   \n",
       "16  17.0                      Assam                               -   315881   \n",
       "17  18.0               Chhattisgarh                          329180   304063   \n",
       "18  19.0                  Jharkhand                          328598   297204   \n",
       "19  20.0                Uttarakhand                               -   245895   \n",
       "20  21.0            Jammu & Kashmir                               -   155956   \n",
       "21  22.0           Himachal Pradesh                          165472   153845   \n",
       "22  23.0                        Goa                           80449    73170   \n",
       "23  24.0                    Tripura                           55984    49845   \n",
       "24  25.0                 Chandigarh                               -    42114   \n",
       "25  26.0                 Puducherry                           38253    34433   \n",
       "26  27.0                  Meghalaya                           36572    33481   \n",
       "27  28.0                     Sikkim                           32496    28723   \n",
       "28  29.0                    Manipur                           31790    27870   \n",
       "29  30.0                   Nagaland                               -    27283   \n",
       "30  31.0          Arunachal Pradesh                               -    24603   \n",
       "31  32.0                    Mizoram                           26503    22287   \n",
       "32  33.0  Andaman & Nicobar Islands                               -        -   \n",
       "\n",
       "     Share GDP ($billion) GSDP (Cr INR at 2011-12 prices)           \n",
       "     18-19           2019                           19-20    18-19  \n",
       "0   13.94%        399.921                               -  2039074  \n",
       "1    8.63%        247.629                         1312929  1215307  \n",
       "2    8.39%        240.726                         1166817  1123982  \n",
       "3    7.96%        228.290                               -  1186379  \n",
       "4    7.91%        226.806                         1156039  1091077  \n",
       "5    5.77%        165.556                          793223   739525  \n",
       "6    4.99%        143.179                          711627   677428  \n",
       "7    4.57%        131.083                          672018   621301  \n",
       "8    4.56%        130.791                          663258   612828  \n",
       "9    4.29%        122.977                          561801   522009  \n",
       "10   4.14%        118.733                               -   559412  \n",
       "11   4.10%        117.703                          634408   590569  \n",
       "12   3.89%        111.519                          572240   531085  \n",
       "13   2.81%         80.562                          414977   375651  \n",
       "14   2.79%         79.957                          418868   397669  \n",
       "15   2.58%         74.098                          396499   376877  \n",
       "16   1.67%         47.982                               -   234048  \n",
       "17   1.61%         46.187                          243477   231182  \n",
       "18   1.57%         45.145                          240036   224986  \n",
       "19   1.30%         37.351                               -   193273  \n",
       "20   0.83%         23.690                               -   112755  \n",
       "21   0.81%         23.369                          124403   117851  \n",
       "22   0.39%         11.115                           63408    57787  \n",
       "23   0.26%          7.571                           40583    36963  \n",
       "24   0.22%          6.397                               -    31192  \n",
       "25   0.18%          5.230                           25093    23013  \n",
       "26   0.18%          5.086                           26695    24682  \n",
       "27   0.15%          4.363                           20017    18722  \n",
       "28   0.15%          4.233                           20673    19300  \n",
       "29   0.14%          4.144                               -    17647  \n",
       "30   0.13%          3.737                               -    16676  \n",
       "31   0.12%          3.385                           18797    16478  \n",
       "32       -              -                               -        -  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the information of driver for accesig the driver for automation\n",
    "driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "\n",
    "#naviagting to the url\n",
    "driver.get('http://statisticstimes.com/')\n",
    "\n",
    "#now we have to navigate to the economy dropdown from there we have to select the state wise GDP of india\n",
    "#here we need to perform click in order to access the dropdown\n",
    "driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/button').click()\n",
    "\n",
    "#now from that dropdown we have to select the indian economy \n",
    "driver.find_element_by_xpath('//*[@id=\"top\"]/div[2]/div[2]/div/a[3]').click()\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "#now there is a hyper link which leads to another page that contains GDP details of all the states in india\n",
    "driver.find_element_by_xpath('//a[@href=\"india/indian-states-gdp.php\"]').click()\n",
    "\n",
    "#setting the url variable to the link through which we want\n",
    "url = driver.current_url\n",
    "\n",
    "#getting the companents of the page to scrape the details\n",
    "#This is the new url which the current page is and we want it to scrape the currrent page\n",
    "page = requests.get(url)\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)\n",
    "\n",
    "#here we are going to find all the tables using pandas readhtml method\n",
    "tables = soup.find_all('table')\n",
    "\n",
    "#here from a group of tables we are extracting 1st table which is GSDP\n",
    "dfs = pd.read_html(str(tables))[1]\n",
    "\n",
    "#there is an unwanted row in the dataframe so removing it\n",
    "df = dfs.drop(33, axis = 0)\n",
    "\n",
    "#saving the results to csv files for further usage\n",
    "df.to_csv(\"statistics.csv\")\n",
    "\n",
    "#displaying the dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the information of driver for accesig the driver for automation\n",
    "driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "\n",
    "#naviagting to the url\n",
    "driver.get('https://www.github.com')\n",
    "\n",
    "#making the driver wait\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trending  repositories on GitHub today · GitHub\n"
     ]
    }
   ],
   "source": [
    "#now we ahve to navigate to explore tab and from there to trending\n",
    "driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary').click()\n",
    "\n",
    "#here we are clicking on the trending tab so that we are goingt other tab\n",
    "driver.find_element_by_xpath('//a[@href=\"/trending\"]').click()\n",
    "\n",
    "#setting the current url \n",
    "url = driver.current_url\n",
    "\n",
    "#getting the companents of the page to scrape the details\n",
    "#This is the new url which the current page is and we want it to scrape the currrent page\n",
    "page = requests.get(url)\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repo_Tiltle</th>\n",
       "      <th>Repo_Desc</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>Languages_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>public-apis</td>\n",
       "      <td>A collective list of free APIs</td>\n",
       "      <td>129,825</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>escape2020</td>\n",
       "      <td>ESCAPE Summer School 2021</td>\n",
       "      <td>93</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>17,604</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jhu-ep-coursera</td>\n",
       "      <td>Example code for HTML, CSS, and Javascript for...</td>\n",
       "      <td>5,835</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>slidevjs</td>\n",
       "      <td>Presentation Slides for Developers (Beta)</td>\n",
       "      <td>13,566</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TuSimple</td>\n",
       "      <td>A Vue 3 Component Library. Fairly Complete. Cu...</td>\n",
       "      <td>2,060</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mattnotmax</td>\n",
       "      <td>A list of cyber-chef recipes and curated links</td>\n",
       "      <td>922</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>taosdata</td>\n",
       "      <td>An open-source big data platform designed and ...</td>\n",
       "      <td>15,268</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Charmve</td>\n",
       "      <td>《计算机视觉实战演练：算法与应用》中文电子书、源码、读者交流社区（更新中，可以先 star）</td>\n",
       "      <td>293</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PaddlePaddle</td>\n",
       "      <td>An NLP library with Awesome pre-trained Transf...</td>\n",
       "      <td>941</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>peng-zhihui</td>\n",
       "      <td>Master the command line, in one page</td>\n",
       "      <td>815</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>jlevy</td>\n",
       "      <td>Efficient and minimal collaborative code edito...</td>\n",
       "      <td>91,199</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ekzhang</td>\n",
       "      <td>Build cross-platform desktop apps with JavaScr...</td>\n",
       "      <td>1,149</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>electron</td>\n",
       "      <td>🚀✨ Help beginners to contribute to open source...</td>\n",
       "      <td>93,761</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>firstcontributions</td>\n",
       "      <td>✍ It has never been so easy to document your t...</td>\n",
       "      <td>19,268</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KibaeKim</td>\n",
       "      <td>Transacted Hollowing - a PE injection techniqu...</td>\n",
       "      <td>421</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pedronauck</td>\n",
       "      <td>Create Beautiful Tkinter GUIs by Drag and Drop ☄️</td>\n",
       "      <td>21,115</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hasherezade</td>\n",
       "      <td>Terminal based presentation tool</td>\n",
       "      <td>197</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Repo_Tiltle                                          Repo_Desc  \\\n",
       "0          public-apis                     A collective list of free APIs   \n",
       "1           escape2020                          ESCAPE Summer School 2021   \n",
       "2             facebook  An open-source C++ library developed and used ...   \n",
       "3      jhu-ep-coursera  Example code for HTML, CSS, and Javascript for...   \n",
       "4             slidevjs          Presentation Slides for Developers (Beta)   \n",
       "5             TuSimple  A Vue 3 Component Library. Fairly Complete. Cu...   \n",
       "6           mattnotmax     A list of cyber-chef recipes and curated links   \n",
       "7             taosdata  An open-source big data platform designed and ...   \n",
       "8              Charmve     《计算机视觉实战演练：算法与应用》中文电子书、源码、读者交流社区（更新中，可以先 star）   \n",
       "9         PaddlePaddle  An NLP library with Awesome pre-trained Transf...   \n",
       "10         peng-zhihui               Master the command line, in one page   \n",
       "11               jlevy  Efficient and minimal collaborative code edito...   \n",
       "12             ekzhang  Build cross-platform desktop apps with JavaScr...   \n",
       "13            electron  🚀✨ Help beginners to contribute to open source...   \n",
       "14  firstcontributions  ✍ It has never been so easy to document your t...   \n",
       "15            KibaeKim  Transacted Hollowing - a PE injection techniqu...   \n",
       "16          pedronauck  Create Beautiful Tkinter GUIs by Drag and Drop ☄️   \n",
       "17         hasherezade                   Terminal based presentation tool   \n",
       "\n",
       "   Contribution    Languages_used  \n",
       "0       129,825            Python  \n",
       "1            93  Jupyter Notebook  \n",
       "2        17,604               C++  \n",
       "3         5,835        JavaScript  \n",
       "4        13,566        TypeScript  \n",
       "5         2,060        TypeScript  \n",
       "6           922                 C  \n",
       "7        15,268  Jupyter Notebook  \n",
       "8           293            Python  \n",
       "9           941              Rust  \n",
       "10          815               C++  \n",
       "11       91,199        JavaScript  \n",
       "12        1,149        TypeScript  \n",
       "13       93,761                 C  \n",
       "14       19,268            Python  \n",
       "15          421                Go  \n",
       "16       21,115            Python  \n",
       "17          197        TypeScript  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creaing empty lists for storing the results\n",
    "Repo_title = []\n",
    "Repo_desc = []\n",
    "contri_count = []\n",
    "Languages_used = []\n",
    "\n",
    "#getting description details\n",
    "desc = soup.find_all(\"p\", class_=\"col-9 color-text-secondary my-1 pr-4\")\n",
    "for i in desc:\n",
    "    Repo_desc.append(i.text.replace(\"\\n\", \"\").strip())\n",
    "    \n",
    "#getting language details\n",
    "    \n",
    "language = soup.find_all(\"span\", class_=\"d-inline-block ml-0 mr-3\")\n",
    "for i in language:\n",
    "    Languages_used.append(i.text.replace(\"\\n\", \"\").strip())\n",
    "    \n",
    "#getting the title details \n",
    "    \n",
    "title = soup.find_all(\"span\", class_=\"text-normal\")\n",
    "for i in title[26:]:\n",
    "    Repo_title.append(i.text.replace(\"/\", '').strip())\n",
    "    \n",
    "#getting contribution details\n",
    "    \n",
    "contri = soup.find_all('a', class_=\"Link--muted d-inline-block mr-3\")\n",
    "for i in contri[::2]:\n",
    "    contri_count.append(i.text.replace(\"\\n\", \"\").strip())\n",
    "\n",
    "#creating the dataframe for storing the results\n",
    "\n",
    "details = pd.DataFrame({})\n",
    "details[\"Repo_Tiltle\"] = Repo_title[:18]\n",
    "details[\"Repo_Desc\"] = Repo_desc[:18]\n",
    "details[\"Contribution\"] = contri_count[:18]\n",
    "details[\"Languages_used\"] = Languages_used[:18]\n",
    "\n",
    "#saving to csv format\n",
    "\n",
    "details.to_csv(\"details.csv\")\n",
    "    \n",
    "#displaying results\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "6. Scrape the details of top 100 songs on billiboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hot 100 Chart | Billboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last_Week_Rank</th>\n",
       "      <th>Peak</th>\n",
       "      <th>Week_On_Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Butter</td>\n",
       "      <td>BTS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good 4 U</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa Featuring DaBaby</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leave The Door Open</td>\n",
       "      <td>Silk Sonic (Bruno Mars &amp; Anderson .Paak)</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>All I Know So Far</td>\n",
       "      <td>P!nk</td>\n",
       "      <td>87</td>\n",
       "      <td>74</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hold On</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>86</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wasted On You</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>98</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Outside</td>\n",
       "      <td>MO3 X OG Bobby Billions</td>\n",
       "      <td>-</td>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Botella Tras Botella</td>\n",
       "      <td>Gera MX + Christian Nodal</td>\n",
       "      <td>-</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Song                                    Artist  \\\n",
       "0                 Butter                                       BTS   \n",
       "1               Good 4 U                            Olivia Rodrigo   \n",
       "2             Levitating                 Dua Lipa Featuring DaBaby   \n",
       "3    Leave The Door Open  Silk Sonic (Bruno Mars & Anderson .Paak)   \n",
       "4        Save Your Tears                The Weeknd & Ariana Grande   \n",
       "..                   ...                                       ...   \n",
       "95     All I Know So Far                                      P!nk   \n",
       "96               Hold On                             Justin Bieber   \n",
       "97         Wasted On You                             Morgan Wallen   \n",
       "98               Outside                   MO3 X OG Bobby Billions   \n",
       "99  Botella Tras Botella                 Gera MX + Christian Nodal   \n",
       "\n",
       "   Last_Week_Rank Peak Week_On_Board  \n",
       "0               1    1             2  \n",
       "1               2    1             3  \n",
       "2               4    2            35  \n",
       "3               5    1            13  \n",
       "4               7    1            25  \n",
       "..            ...  ...           ...  \n",
       "95             87   74             3  \n",
       "96             86   20            13  \n",
       "97             98    9            19  \n",
       "98              -   99             1  \n",
       "99              -   60             4  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the information of driver for accesig the driver for automation\n",
    "driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "\n",
    "#naviagting to the url\n",
    "driver.get('https://www.billboard.com/')\n",
    "\n",
    "#making the driver wait\n",
    "time.sleep(5)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#now we ahve to navigate charts and explore to hot100\n",
    "driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/header/div/ul/li[1]/a').click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "#here we are clicking on the hot 100\n",
    "driver.find_element_by_xpath('//*[@id=\"main\"]/div[2]/div/div[1]/a/div[2]').click()\n",
    "\n",
    "#setting the current url \n",
    "url = driver.current_url\n",
    "\n",
    "#getting the companents of the page to scrape the details\n",
    "#This is the new url which the current page is and we want it to scrape the currrent page\n",
    "page = requests.get(url)\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)\n",
    "\n",
    "#creating the empty list for storing the data\n",
    "Song_name = []\n",
    "Artist_name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []\n",
    "\n",
    "#getting the name details of the songs\n",
    "name = soup.find_all('span', class_=\"chart-element__information__song text--truncate color--primary\")\n",
    "for i in name:\n",
    "    Song_name.append(i.text)\n",
    "    \n",
    "#getting the artistname\n",
    "artist = soup.find_all('span', class_=\"chart-element__information__artist text--truncate color--secondary\")\n",
    "for i in artist:\n",
    "    Artist_name.append(i.text)\n",
    "    \n",
    "#gettn ast week peak details   \n",
    "last = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--last\"]')\n",
    "for i in last:\n",
    "    Last_week_rank.append(i.text) \n",
    "    \n",
    "#gathering peak data\n",
    "peak = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]')\n",
    "for i in peak:\n",
    "    Peak_rank.append(i.text)\n",
    "    \n",
    "\n",
    "#gaathering week data\n",
    "week = driver.find_elements_by_xpath('//div[@class=\"chart-element__meta text--center color--secondary text--week\"]')\n",
    "for i in week:\n",
    "    Weeks_on_board.append(i.text)\n",
    "    \n",
    "#creating a dataframe with the data we shared\n",
    "billbord = pd.DataFrame({})\n",
    "billbord[\"Song\"] = Song_name\n",
    "billbord[\"Artist\"] = Artist_name\n",
    "billbord[\"Last_Week_Rank\"] = Last_week_rank\n",
    "billbord[\"Peak\"] = Peak_rank\n",
    "billbord[\"Week_On_Board\"] = Weeks_on_board\n",
    "\n",
    "#saving to csv format\n",
    "billbord.to_csv(\"hot100.csv\")\n",
    "\n",
    "#displaying the result\n",
    "billbord\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "7. Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data science Recruiters - Data science Placement Consultants - Naukri.com\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills_they_hire_for</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Classic ASP Developer,   Internet Marketin...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>.Net,   Java,   Data Science,   Linux Admi...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Data Science,   Artificial Intelligence,  ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Mean Stack,   javascript,   angularjs,   m...</td>\n",
       "      <td>Ahmedabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Hadoop,   Spark,   Digital Strategy,   Dat...</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Analytics,   Business Intelligence,   Busi...</td>\n",
       "      <td>Vadodara / Baroda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>Machine Learning,   algorithms,   Go Gette...</td>\n",
       "      <td>Trivandrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Technical Training,   Software Development...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Software Development,   It Sales,   Accoun...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Qa,   Ui/ux,   Java Developer,   Java Arch...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Business Intelligence,   Data Warehousing,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Office Administration,   Hr Administration...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Qlikview,   Qlik Sense,   Microsoft Azure,...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Social Media,   digital media maketing,   ...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Big Data,   Hadoop,   Data Analytics,   Da...</td>\n",
       "      <td>Bhopal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Telecalling,   Client Interaction,   Marke...</td>\n",
       "      <td>Navi Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Data Science</td>\n",
       "      <td>Cochin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Corporate Sales,   Software Development,  ...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>Data Analytics,   Data Science,   Machine ...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Data Science,   Machine Learning,   Python...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Data Science,   Artificial Intelligence,  ...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>Big Data,   Data Science,   Artificial Int...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Java,   Net,   Angularjs,   Hr,   Infrastr...</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Software Architecture,   Vp Engineering,  ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Data Science,   Hadoop,   Rpas,   Devops, ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>Signal Processing,   Machine Learning,   N...</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Web Technologies,   Project Management,   ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Data Science,   Artificial Intelligence,  ...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Server Administartion,   Verilog,   Vhdl, ...</td>\n",
       "      <td>Mysoru / Mysore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Data Analytics,   Managed Services,   Team...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Data Science,   Machine Learning,   Big Da...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Radha Manivasagam</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Techcovery</td>\n",
       "      <td>Python,   Artificial Intelligence,   Machi...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Prateek Kumar</td>\n",
       "      <td>Head</td>\n",
       "      <td>Trisect</td>\n",
       "      <td>Java,   Python,   Angularjs,   Software Te...</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Machine Learning,   Artificial Intelligenc...</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>C,   C++,   Artificial Intelligence,   Pyt...</td>\n",
       "      <td>Aligarh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>Relationship Management,   Retail Sales,  ...</td>\n",
       "      <td>Salt Lake City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Data Science,   Software Engineering</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Data Science,   Big Data Analytics,   Digi...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Data Science,   Recruitment,   Salary</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>B.Tech,   Tableau,   Statistics,   R,   An...</td>\n",
       "      <td>Indore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Software Development,   Business Intellige...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Data Science,   Node.js,   Angularjs</td>\n",
       "      <td>MYSORE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Data Science,   Media Marketing,   Resourc...</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Data Analysis,   Learning,   Data Science,...</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>Java,   Hadoop,   R,   Machine Learning,  ...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Software Development,   Core Java,   Unit ...</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>Machine Learning,   Data Science,   Produc...</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5   Abhishek - Only Analytics Hiring - India and    \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                Kalpana Dumpala   \n",
       "11                                        Mubarak   \n",
       "12                                 Kushal Rastogi   \n",
       "13                                    Ruchi Dhote   \n",
       "14                             Mahesh Babu Channa   \n",
       "15                                   Kapil Devang   \n",
       "16                                  Manisha Yadav   \n",
       "17                                    Riya Rajesh   \n",
       "18                           Rashmi Bhattacharjee   \n",
       "19                                  Faizan Kareem   \n",
       "20                                 Rithika dadwal   \n",
       "21                                  Azahar Shaikh   \n",
       "22                             Sandhya Khandagale   \n",
       "23                                      Shaun Rao   \n",
       "24                                          Manas   \n",
       "25                                          kumar   \n",
       "26                                   Sunil Vedula   \n",
       "27                                    Rajat Kumar   \n",
       "28                                    Priya Khare   \n",
       "29                                Dhruv Dev Dubey   \n",
       "30                                      Jayanth N   \n",
       "31                                       SREEDHAR   \n",
       "32                              Radha Manivasagam   \n",
       "33                                  Prateek Kumar   \n",
       "34                                    Amit Sharma   \n",
       "35                                          Kanan   \n",
       "36                           Shashikant Chaudhary   \n",
       "37                                           Brad   \n",
       "38                                   Rutuja Pawar   \n",
       "39                            Madhusudhan Sridhar   \n",
       "40                                    Ankit Sinha   \n",
       "41                                 Gaurav Chouhan   \n",
       "42                                   Rashi Kacker   \n",
       "43                                        Ashwini   \n",
       "44                                   Balaji Kolli   \n",
       "45                                 Rajani Nagaraj   \n",
       "46                                    ROHIT Kumar   \n",
       "47                                 Amir Chowdhury   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                     Executive Hiring   \n",
       "11                           Company HR   \n",
       "12                           Company HR   \n",
       "13  Senior Executive Talent Acquisition   \n",
       "14                         HR Team Lead   \n",
       "15                           HR Manager   \n",
       "16                         HR Executive   \n",
       "17           Manager Talent Acquisition   \n",
       "18                              HR Head   \n",
       "19                           HR MANAGER   \n",
       "20                         HR Recruiter   \n",
       "21                    Company Recruiter   \n",
       "22                         HR Recruiter   \n",
       "23              Manager Human Resources   \n",
       "24              Lead Talent acquisition   \n",
       "25                           Proprietor   \n",
       "26                                  CEO   \n",
       "27                          Founder CEO   \n",
       "28                       Senior Manager   \n",
       "29             Company Recruitment Head   \n",
       "30                      Project Manager   \n",
       "31               Recruitment Consultant   \n",
       "32                         HR Executive   \n",
       "33                                 Head   \n",
       "34                           Consultant   \n",
       "35         senior technology instructor   \n",
       "36             HR Recruiter/HR Excutive   \n",
       "37        Manager, Technical Recruiting   \n",
       "38                  Technical Recruiter   \n",
       "39                      Erp Implementer   \n",
       "40                       Head Analytics   \n",
       "41              Chief Technical Officer   \n",
       "42                   Sr Product Manager   \n",
       "43             Director Global Delivery   \n",
       "44                           Co Founder   \n",
       "45                           HR Manager   \n",
       "46                            Architect   \n",
       "47                     Managing Partner   \n",
       "\n",
       "                                           Company  \\\n",
       "0                             Data Science Network   \n",
       "1                    Shore Infotech India Pvt. Ltd   \n",
       "2                         MARSIAN Technologies LLP   \n",
       "3            Enerlytics Software Solutions Pvt Ltd   \n",
       "4                                  LibraryXProject   \n",
       "5       Apidel Technologies Division of Transpower   \n",
       "6                                             IFMR   \n",
       "7                      Techvantage Systems Pvt Ltd   \n",
       "8                       Weupskill- Live Wire India   \n",
       "9                 CBL Data Science Private Limited   \n",
       "10                              Innominds Software   \n",
       "11                                        MoneyTap   \n",
       "12              QuantMagnum Technologies Pvt. Ltd.   \n",
       "13                           Bristlecone India Ltd   \n",
       "14                               SocialPrachar.com   \n",
       "15                                  BISP Solutions   \n",
       "16                                        Easi Tax   \n",
       "17                     Novelworx Digital Solutions   \n",
       "18         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...   \n",
       "19                   FirstTech Consaltants Pvt.Ltd   \n",
       "20                                Affine Analytics   \n",
       "21                 NEAL ANALYTICS SERVICES PVT LTD   \n",
       "22                 Compumatrice Multimedia Pvt Ltd   \n",
       "23                              Exela Technologies   \n",
       "24      Autumn Leaf Consulting Services Private...   \n",
       "25                                         trainin   \n",
       "26                            Nanoprecise Sci Corp   \n",
       "27                  R.S Consultancy &amp; Services   \n",
       "28                          Independent Consultant   \n",
       "29                                    Confidential   \n",
       "30        Dollarbird Information Services Pvt, Ltd   \n",
       "31     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "32                                      Techcovery   \n",
       "33                                         Trisect   \n",
       "34                                 ASCO consulting   \n",
       "35                                         NY INST   \n",
       "36  3D India Staffing Research &amp; Consulting...   \n",
       "37                                     O.C. Tanner   \n",
       "38                                   Demand Matrix   \n",
       "39                             MADHUSUDHAN SRIDHAR   \n",
       "40                                  Suntech Global   \n",
       "41                        Strategic Consulting Lab   \n",
       "42                            Impel Labs Pvt. Ltd.   \n",
       "43                                    MRP Advisers   \n",
       "44                   Saras Solutions India Pvt Ltd   \n",
       "45                                     WildJasmine   \n",
       "46                             LNT Private Limited   \n",
       "47                                     Granular.ai   \n",
       "\n",
       "                                 Skills_they_hire_for  \\\n",
       "0       Classic ASP Developer,   Internet Marketin...   \n",
       "1       .Net,   Java,   Data Science,   Linux Admi...   \n",
       "2       Data Science,   Artificial Intelligence,  ...   \n",
       "3       Mean Stack,   javascript,   angularjs,   m...   \n",
       "4       Hadoop,   Spark,   Digital Strategy,   Dat...   \n",
       "5       Analytics,   Business Intelligence,   Busi...   \n",
       "6                                    Data Science       \n",
       "7       Machine Learning,   algorithms,   Go Gette...   \n",
       "8       Technical Training,   Software Development...   \n",
       "9       Software Development,   It Sales,   Accoun...   \n",
       "10      Qa,   Ui/ux,   Java Developer,   Java Arch...   \n",
       "11      Business Intelligence,   Data Warehousing,...   \n",
       "12      Office Administration,   Hr Administration...   \n",
       "13      Qlikview,   Qlik Sense,   Microsoft Azure,...   \n",
       "14      Social Media,   digital media maketing,   ...   \n",
       "15      Big Data,   Hadoop,   Data Analytics,   Da...   \n",
       "16      Telecalling,   Client Interaction,   Marke...   \n",
       "17                                   Data Science       \n",
       "18      Corporate Sales,   Software Development,  ...   \n",
       "19      Data Analytics,   Data Science,   Machine ...   \n",
       "20      Data Science,   Machine Learning,   Python...   \n",
       "21      Data Science,   Artificial Intelligence,  ...   \n",
       "22      Big Data,   Data Science,   Artificial Int...   \n",
       "23      Java,   Net,   Angularjs,   Hr,   Infrastr...   \n",
       "24      Software Architecture,   Vp Engineering,  ...   \n",
       "25      Data Science,   Hadoop,   Rpas,   Devops, ...   \n",
       "26      Signal Processing,   Machine Learning,   N...   \n",
       "27      Web Technologies,   Project Management,   ...   \n",
       "28      Data Science,   Artificial Intelligence,  ...   \n",
       "29      Server Administartion,   Verilog,   Vhdl, ...   \n",
       "30      Data Analytics,   Managed Services,   Team...   \n",
       "31      Data Science,   Machine Learning,   Big Da...   \n",
       "32      Python,   Artificial Intelligence,   Machi...   \n",
       "33      Java,   Python,   Angularjs,   Software Te...   \n",
       "34      Machine Learning,   Artificial Intelligenc...   \n",
       "35      C,   C++,   Artificial Intelligence,   Pyt...   \n",
       "36      Relationship Management,   Retail Sales,  ...   \n",
       "37           Data Science,   Software Engineering       \n",
       "38      Data Science,   Big Data Analytics,   Digi...   \n",
       "39          Data Science,   Recruitment,   Salary       \n",
       "40      B.Tech,   Tableau,   Statistics,   R,   An...   \n",
       "41      Software Development,   Business Intellige...   \n",
       "42           Data Science,   Node.js,   Angularjs       \n",
       "43      Data Science,   Media Marketing,   Resourc...   \n",
       "44      Data Analysis,   Learning,   Data Science,...   \n",
       "45      Java,   Hadoop,   R,   Machine Learning,  ...   \n",
       "46      Software Development,   Core Java,   Unit ...   \n",
       "47      Machine Learning,   Data Science,   Produc...   \n",
       "\n",
       "                    Location  \n",
       "0                      Delhi  \n",
       "1   Hyderabad / Secunderabad  \n",
       "2                       Pune  \n",
       "3                  Ahmedabad  \n",
       "4              UK - (london)  \n",
       "5          Vadodara / Baroda  \n",
       "6                    Chennai  \n",
       "7                 Trivandrum  \n",
       "8                     Indore  \n",
       "9      Bengaluru / Bangalore  \n",
       "10  Hyderabad / Secunderabad  \n",
       "11     Bengaluru / Bangalore  \n",
       "12                    Mumbai  \n",
       "13                      Pune  \n",
       "14  Hyderabad / Secunderabad  \n",
       "15                    Bhopal  \n",
       "16               Navi Mumbai  \n",
       "17                    Cochin  \n",
       "18                     Delhi  \n",
       "19  Hyderabad / Secunderabad  \n",
       "20                      Pune  \n",
       "21                      Pune  \n",
       "22                      Pune  \n",
       "23                      Pune  \n",
       "24     Bengaluru / Bangalore  \n",
       "25     Bengaluru / Bangalore  \n",
       "26                     Delhi  \n",
       "27     Bengaluru / Bangalore  \n",
       "28     Bengaluru / Bangalore  \n",
       "29           Mysoru / Mysore  \n",
       "30  Hyderabad / Secunderabad  \n",
       "31     Bengaluru / Bangalore  \n",
       "32                     Noida  \n",
       "33                 New Delhi  \n",
       "34                   Chennai  \n",
       "35                   Aligarh  \n",
       "36            Salt Lake City  \n",
       "37                      Pune  \n",
       "38     Bengaluru / Bangalore  \n",
       "39                    Mumbai  \n",
       "40                    Indore  \n",
       "41     Bengaluru / Bangalore  \n",
       "42                    MYSORE  \n",
       "43  Hyderabad / Secunderabad  \n",
       "44     Bengaluru / Bangalore  \n",
       "45                    Mumbai  \n",
       "46                     Noida  \n",
       "47                    Mumbai  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the information of driver for accesig the driver for automation\n",
    "driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "\n",
    "#naviagting to the url\n",
    "driver.get('https://www.naukri.com/')\n",
    "\n",
    "#making the driver wait\n",
    "time.sleep(5)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#now we ahve to navigate charts and explore to hot100\n",
    "driver.find_element_by_xpath('//*[@id=\"root\"]/div[1]/div/ul[1]/li[2]/a').click()\n",
    "\n",
    "#creating empty lists for storing details\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills_they_hire_for = []\n",
    "Location = []\n",
    "\n",
    "\n",
    "#create window handle ids for acesing all tabs that are active\n",
    "alltabs = driver.window_handles\n",
    "\n",
    "#now iterate through all tabs to fetch data from the site which we want to and have aces to that\n",
    "for tab in alltabs:\n",
    "    driver.switch_to.window(tab)#switching the current tab\n",
    "    if(driver.current_url == \"https://www.naukri.com/hr-recruiters-consultants\"): #validating the url\n",
    "        \n",
    "        #accessing the search to search for datascience\n",
    "        driver.find_element_by_xpath('//*[@id=\"skill\"]/div[1]/div[2]/input').send_keys(\"Data science\")\n",
    "        \n",
    "        #now perform click option \n",
    "        driver.find_element_by_xpath('//*[@id=\"qsbFormBtn\"]').click()\n",
    "        \n",
    "        #get the desired tab url for fetching details \n",
    "        url = driver.current_url\n",
    "\n",
    "        #This is the new url which the current page is and we want it to scrape the currrent page\n",
    "        page = requests.get(url)\n",
    "\n",
    "        #parsing the html data using html parser\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        #printing the most viewed title of the table\n",
    "        print(soup.title.text)\n",
    "        \n",
    "        #getting name details\n",
    "        name = soup.find_all(\"span\", class_=\"fl ellipsis\")\n",
    "        for i in name:\n",
    "            Name.append(i.text)\n",
    "            \n",
    "        #getting designation details\n",
    "        desi = soup.find_all('span', class_=\"ellipsis clr\")\n",
    "        for i in desi:\n",
    "            Designation.append(i.text)\n",
    "            \n",
    "        #getting the company details\n",
    "        compi = [] #created a dummy list for datastorage\n",
    "        comp = soup.find_all('a', class_=\"ellipsis\")\n",
    "        for i in comp:\n",
    "            compi.append(i.text)\n",
    "    \n",
    "        Company = compi[::-1][::2][::-1] \n",
    "        #appending the comany details actually it has mixture with some other values\n",
    "        #so applied indexing to get accurate details\n",
    "        \n",
    "        #getting location details\n",
    "        try:\n",
    "            locat = soup.find_all(\"small\", class_=\"ellipsis\")\n",
    "            for i in locat:\n",
    "                Location.append(i.text)\n",
    "        except:\n",
    "            Location.append(\"---\")\n",
    "            \n",
    "        #fetch skills they hire for\n",
    "        skill = soup.find_all('div', class_=\"hireSec highlightable\")\n",
    "        for i in skill:\n",
    "            Skills_they_hire_for.append(i.text)\n",
    "        \n",
    "            \n",
    "#creating a dataframe to store results        \n",
    "naukari = pd.DataFrame({})\n",
    "naukari[\"Name\"] = Name[:48]\n",
    "naukari[\"Designation\"] = Designation[:48]\n",
    "naukari[\"Company\"] = Company[:48]\n",
    "naukari[\"Skills_they_hire_for\"] = Skills_they_hire_for[:48]\n",
    "naukari[\"Location\"] = Location[:48]\n",
    "\n",
    "#save the dataframe to csv file\n",
    "naukari.to_csv(\"naukari.csv\")\n",
    "\n",
    "#displaying the results\n",
    "naukari\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-\n",
    "compare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The top 100 bestselling books of all time: how does Fifty Shades of Grey compare? | News | theguardian.com \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume Sales</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5094805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4475152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4200654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4179479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3758936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title            Author  \\\n",
       "Rank                                                                        \n",
       "1                                     Da Vinci Code,The        Brown, Dan   \n",
       "2                  Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "3              Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "4             Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "5                                  Fifty Shades of Grey      James, E. L.   \n",
       "...                                                 ...               ...   \n",
       "96                                            Ghost,The    Harris, Robert   \n",
       "97                       Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "98                Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "99    Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "100   Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "     Volume Sales        Publisher                        Genre  \n",
       "Rank                                                             \n",
       "1         5094805       Transworld  Crime, Thriller & Adventure  \n",
       "2         4475152       Bloomsbury           Children's Fiction  \n",
       "3         4200654       Bloomsbury           Children's Fiction  \n",
       "4         4179479       Bloomsbury           Children's Fiction  \n",
       "5         3758936     Random House              Romance & Sagas  \n",
       "...           ...              ...                          ...  \n",
       "96         807311     Random House   General & Literary Fiction  \n",
       "97         794201          Penguin        Food & Drink: General  \n",
       "98         792187  Scholastic Ltd.          Young Adult Fiction  \n",
       "99         791507            Orion           Biography: General  \n",
       "100        791095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the new url which the current page is and we want it to scrape the currrent page\n",
    "page = requests.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)\n",
    "\n",
    "#i am using soup variable tat we stored entire html file and i am searching tables from it\n",
    "table = soup.find_all('table')\n",
    "\n",
    "#now iam using pd.readhtml method from pandas to extract tables, only this methods supprots tabular data only\n",
    "df = pd.read_html(str(table))[0]\n",
    "\n",
    "#dropping 100 th row as there is no use with this\n",
    "book_data = df.drop(100, axis = 0)\n",
    "\n",
    "#setting the rank as index\n",
    "new = book_data.set_index(\"Rank\")\n",
    "\n",
    "#displaying the results \n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 most watched tv shows of all time - IMDb\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>\\nAction, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1,820,550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>\\nDrama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>861,938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>\\nDrama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>873,613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>\\nDrama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>The 100</td>\n",
       "      <td>\\nDrama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>223,666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>Reign</td>\n",
       "      <td>\\nDrama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>44,523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>\\nAdventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>55,008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>\\nCrime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.0</td>\n",
       "      <td>167,309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>\\nComedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>34,843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>\\nDrama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>191,027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Show                            Year  \\\n",
       "0                  Game of Thrones                 Game of Thrones   \n",
       "1                  Stranger Things                 Stranger Things   \n",
       "2                 The Walking Dead                The Walking Dead   \n",
       "3                   13 Reasons Why                  13 Reasons Why   \n",
       "4                          The 100                         The 100   \n",
       "..                             ...                             ...   \n",
       "95                           Reign                           Reign   \n",
       "96  A Series of Unfortunate Events  A Series of Unfortunate Events   \n",
       "97                  Criminal Minds                  Criminal Minds   \n",
       "98           Scream: The TV Series           Scream: The TV Series   \n",
       "99      The Haunting of Hill House      The Haunting of Hill House   \n",
       "\n",
       "                                     Genre  Runtime  Rating      Votes  \n",
       "0   \\nAction, Adventure, Drama               57 min     9.3  1,820,550  \n",
       "1     \\nDrama, Fantasy, Horror               51 min     8.7    861,938  \n",
       "2    \\nDrama, Horror, Thriller               44 min     8.2    873,613  \n",
       "3   \\nDrama, Mystery, Thriller               60 min     7.6    262,376  \n",
       "4     \\nDrama, Mystery, Sci-Fi               43 min     7.6    223,666  \n",
       "..                                     ...      ...     ...        ...  \n",
       "95            \\nDrama, Fantasy               42 min     7.5     44,523  \n",
       "96  \\nAdventure, Comedy, Drama               50 min     7.8     55,008  \n",
       "97     \\nCrime, Drama, Mystery               42 min     8.0    167,309  \n",
       "98      \\nComedy, Crime, Drama               45 min     7.1     34,843  \n",
       "99    \\nDrama, Horror, Mystery              572 min     8.6    191,027  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the information of driver for accesig the driver for automation\n",
    "driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "\n",
    "#naviagting to the url\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')\n",
    "\n",
    "#making the driver wait\n",
    "time.sleep(5)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#This is the new url which the current page is and we want it to scrape the currrent page\n",
    "page = requests.get('https://www.imdb.com/list/ls095964455/')\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)\n",
    "\n",
    "#list t ostore the data\n",
    "movie_name = []\n",
    "year = []\n",
    "genre = []\n",
    "runtime = []\n",
    "IMDB_rating = [] #empty list\n",
    "votes = []\n",
    "\n",
    "#gathering the movie name and year\n",
    "list1 = soup.find_all('h3', class_=\"lister-item-header\")\n",
    "for i in list1:\n",
    "    for j in i.find_all(\"a\"):\n",
    "        movie_name.append(j.text)\n",
    "        \n",
    "    for k in i.find_all(\"span\", class_=\"lister-item-year text-muted unbold\"):\n",
    "        year.append(j.text.replace(\"(\", '').replace(\")\", ''))\n",
    "\n",
    "#gathering the length and genre\n",
    "length = soup.find_all(\"p\", class_=\"text-muted text-small\")\n",
    "for i in length:\n",
    "    for j in i.find_all(\"span\", class_=\"runtime\"):\n",
    "        runtime.append(j.text)\n",
    "        \n",
    "    for k in i.find_all(\"span\", class_=\"genre\"):\n",
    "        genre.append(k.text)\n",
    "\n",
    "# IMDB Rating\n",
    "rating = soup.find_all(\"div\",class_=\"ipl-rating-star small\")\n",
    "\n",
    "# scrape text from rating web element\n",
    "for i in rating:\n",
    "      IMDB_rating.append(float(i.text))\n",
    "        \n",
    "voti = driver.find_elements_by_xpath('//span[@name=\"nv\"]')\n",
    "for i in voti:\n",
    "    votes.append(i.text)\n",
    "    \n",
    "#creating the dataframe to store the result    \n",
    "series = pd.DataFrame({})\n",
    "series[\"Show\"] = movie_name\n",
    "series[\"Year\"] = year\n",
    "series[\"Genre\"] = genre\n",
    "series[\"Runtime\"] = runtime\n",
    "series[\"Rating\"] = IMDB_rating\n",
    "series[\"Votes\"] = votes\n",
    "\n",
    "#saving to csv file\n",
    "series.to_csv(\"series.csv\")\n",
    "\n",
    "#displaying the result\n",
    "series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "10. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCI Machine Learning Repository: Data Sets\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Data_Types</th>\n",
       "      <th>Default_Task</th>\n",
       "      <th>Attribute_Types</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>in-vehicle coupon recommendation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12684</td>\n",
       "      <td>23</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>Gait Classification</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>48</td>\n",
       "      <td>321</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>Wikipedia Math Essentials</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>Synchronous Machine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Name    Data_Types         Default_Task  \\\n",
       "1                             Abalone  Multivariate       Classification   \n",
       "2                               Adult  Multivariate       Classification   \n",
       "3                           Annealing  Multivariate       Classification   \n",
       "4        Anonymous Microsoft Web Data           NaN  Recommender-Systems   \n",
       "5                          Arrhythmia  Multivariate       Classification   \n",
       "..                                ...           ...                  ...   \n",
       "584  in-vehicle coupon recommendation  Multivariate       Classification   \n",
       "585               Gait Classification  Multivariate       Classification   \n",
       "586         Wikipedia Math Essentials   Time-Series           Regression   \n",
       "587         Wikipedia Math Essentials   Time-Series           Regression   \n",
       "588      Synchronous Machine Data Set  Multivariate           Regression   \n",
       "\n",
       "                Attribute_Types Instances Attributes  Year  \n",
       "1    Categorical, Integer, Real      4177          8  1995  \n",
       "2          Categorical, Integer     48842         14  1996  \n",
       "3    Categorical, Integer, Real       798         38   NaN  \n",
       "4                   Categorical     37711        294  1998  \n",
       "5    Categorical, Integer, Real       452        279  1998  \n",
       "..                          ...       ...        ...   ...  \n",
       "584                         NaN     12684         23  2020  \n",
       "585                        Real        48        321  2020  \n",
       "586                        Real       731       1068  2021  \n",
       "587                        Real       731       1068  2021  \n",
       "588                        Real       557          5  2021  \n",
       "\n",
       "[588 rows x 7 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting the information of driver for accesig the driver for automation\n",
    "driver = webdriver.Chrome('/home/santosh/Downloads/chromedriver_linux64/chromedriver')\n",
    "\n",
    "#naviagting to the url\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "\n",
    "#making the driver wait\n",
    "time.sleep(5)\n",
    "\n",
    "#maximizing the window\n",
    "driver.find_element_by_xpath(\"/html/body/table[1]/tbody/tr/td[2]/span[2]\").click()\n",
    "\n",
    "#setting the current url \n",
    "url = driver.current_url\n",
    "\n",
    "#getting the companents of the page to scrape the details\n",
    "#This is the new url which the current page is and we want it to scrape the currrent page\n",
    "page = requests.get(url)\n",
    "\n",
    "#parsing the html data using html parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "#printing the most viewed title of the table\n",
    "print(soup.title.text)\n",
    "\n",
    "#lest scrape the data\n",
    "table= soup.find_all('table')\n",
    "\n",
    "#lest scrape the data\n",
    "table= soup.find_all('table', cellpadding=\"5\")\n",
    "\n",
    "#We are using read_htmlmethd in pandas tosore the data\n",
    "dfs = pd.read_html(str(table))[0]\n",
    "\n",
    "#We dont need 1 st row so dropping it\n",
    "data = dfs.drop(0, axis = 0)\n",
    "\n",
    "#setting the columns names\n",
    "data.columns = [\"Name\", \"Data_Types\", \"Default_Task\", \"Attribute_Types\",  \"Instances\", \"Attributes\", \"Year\"]\n",
    "\n",
    "#Displaying the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python38364bitbasecondaf5ae4ab580394e4693ea5507f08b0bfd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
